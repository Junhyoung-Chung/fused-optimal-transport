{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e559218-ac5c-432f-8845-964f1876027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.sparse.csgraph import shortest_path, laplacian as sp_laplacian\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import trimesh\n",
    "import ot\n",
    "import ot.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfa52f18-bc97-4192-91a8-c4d8a6a8d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code')\n",
    "import FOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f892e3d-c819-44c5-b377-6d95f9b6d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = Path('MPI-FAUST/training/registrations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6023442-05c4-433d-bdeb-4ce63e127d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ply_mesh(p):\n",
    "    \"\"\"\n",
    "    p: Path to .ply\n",
    "    return: (V, F) with V:(n,3) float64, F:(m,3) int\n",
    "    \"\"\"\n",
    "    m = trimesh.load_mesh(str(p), process=False)\n",
    "    # trimesh는 faces가 (m,3), vertices가 (n,3)\n",
    "    V = np.asarray(m.vertices, dtype=np.float64)\n",
    "    F = np.asarray(m.faces, dtype=np.int32)\n",
    "    return V, F\n",
    "\n",
    "def to_mesh(V, F, colors=None):\n",
    "    mesh = o3d.geometry.TriangleMesh(\n",
    "        o3d.utility.Vector3dVector(V),\n",
    "        o3d.utility.Vector3iVector(F)\n",
    "    )\n",
    "    mesh.compute_vertex_normals()\n",
    "    if colors is not None:\n",
    "        mesh.vertex_colors = o3d.utility.Vector3dVector(colors)\n",
    "    return mesh\n",
    "\n",
    "def transfer_colors_soft(T, colors_src): \n",
    "    w = T.sum(0, keepdims=True) + 1e-12 \n",
    "    colors_t = (T.T @ colors_src) / w.T \n",
    "    return np.clip(colors_t, 0, 1) \n",
    "\n",
    "def build_adj_from_mesh(V: np.ndarray, F: np.ndarray) -> csr_matrix:\n",
    "    \"\"\"\n",
    "    V: (n, 3) vertices\n",
    "    F: (m, 3) faces (triangle indices, int)\n",
    "    return: sparse (n, n) weighted adjacency, weight = edge length\n",
    "    \"\"\"\n",
    "    n = V.shape[0]\n",
    "    i0, i1, i2 = F[:, 0], F[:, 1], F[:, 2]\n",
    "\n",
    "    edges = np.vstack([\n",
    "        np.stack([i0, i1], axis=1),\n",
    "        np.stack([i1, i2], axis=1),\n",
    "        np.stack([i2, i0], axis=1),\n",
    "    ])\n",
    "\n",
    "    # make it undirected\n",
    "    edges = np.vstack([edges, edges[:, ::-1]])\n",
    "\n",
    "    p0 = V[edges[:, 0]]\n",
    "    p1 = V[edges[:, 1]]\n",
    "    lengths = np.linalg.norm(p0 - p1, axis=1)\n",
    "\n",
    "    A = coo_matrix((lengths, (edges[:, 0], edges[:, 1])), shape=(n, n))\n",
    "    return A.tocsr()\n",
    "\n",
    "def compute_fpfh_from_mesh(\n",
    "    V: np.ndarray,\n",
    "    F: np.ndarray,\n",
    "    normal_radius_scale: float = 0.02,\n",
    "    fpfh_radius_scale: float = 0.04,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    open3d 기본 기능로 가능한 피처: FPFH\n",
    "    return: (n, d) = (n, 33)\n",
    "    \"\"\"\n",
    "    # mesh -> o3d\n",
    "    mesh = o3d.geometry.TriangleMesh()\n",
    "    mesh.vertices = o3d.utility.Vector3dVector(V)\n",
    "    mesh.triangles = o3d.utility.Vector3iVector(F.astype(np.int32))\n",
    "    mesh.compute_vertex_normals()\n",
    "\n",
    "    # vertex를 point cloud로\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(V)\n",
    "    pcd.normals = mesh.vertex_normals  # 있어야 FPFH가 잘 됨\n",
    "\n",
    "    # bbox 기반으로 radius 정규화\n",
    "    bbox = mesh.get_axis_aligned_bounding_box()\n",
    "    diag = np.linalg.norm(\n",
    "        np.array(bbox.get_max_bound()) - np.array(bbox.get_min_bound())\n",
    "    )\n",
    "    n_radius = normal_radius_scale * diag\n",
    "    f_radius = fpfh_radius_scale * diag\n",
    "\n",
    "    # normal은 이미 있고, 그래도 찾기 파라미터 명시\n",
    "    pcd.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "            radius=n_radius, max_nn=30\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(\n",
    "            radius=f_radius, max_nn=100\n",
    "        ),\n",
    "    )\n",
    "    # fpfh.data: (33, n)\n",
    "    feats = np.asarray(fpfh.data).T  # (n, 33)\n",
    "    return feats\n",
    "\n",
    "# --- 1) heat kernel helper: sparse도 받게 ----\n",
    "def heat_kernel_from_adj(\n",
    "    A,\n",
    "    t=1.0,\n",
    "    lap='rw',          # 'rw' or 'sym'\n",
    "    method='taylor',   # 지금은 taylor만 있다고 치자\n",
    "    order=2,\n",
    "    renormalize=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    A : (n,n) dense or sparse adjacency\n",
    "    return: (n,n) dense heat kernel\n",
    "    \"\"\"\n",
    "    # 0. sparse면 dense로\n",
    "    if sp.issparse(A):\n",
    "        A = A.tocsr()\n",
    "\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # 1. Laplacian 만들기\n",
    "    if lap == 'rw':\n",
    "        # random-walk L = I - D^{-1} A\n",
    "        if sp.issparse(A):\n",
    "            deg = np.array(A.sum(axis=1)).ravel()\n",
    "            invdeg = 1.0 / np.clip(deg, 1e-12, None)\n",
    "            # L_rw = I - D^{-1}A\n",
    "            # dense로 할 거니까 여기서 곧 toarray\n",
    "            A_dense = A.toarray()\n",
    "            L = np.eye(n) - (invdeg[:, None] * A_dense)\n",
    "        else:\n",
    "            deg = A.sum(axis=1)\n",
    "            invdeg = 1.0 / np.clip(deg, 1e-12, None)\n",
    "            L = np.eye(n) - (invdeg[:, None] * A)\n",
    "    else:  # 'sym'\n",
    "        # symmetric Laplacian: L = D - A\n",
    "        if sp.issparse(A):\n",
    "            L = sp_laplacian(A, normed=False).toarray()\n",
    "        else:\n",
    "            deg = A.sum(axis=1)\n",
    "            L = np.diag(deg) - A\n",
    "\n",
    "    I = np.eye(n)\n",
    "    if method == 'taylor':\n",
    "        if order == 2:\n",
    "            K = I - t * L + 0.5 * (t ** 2) * (L @ L)\n",
    "        else:\n",
    "            K = I - t * L\n",
    "    else:\n",
    "        # 필요하면 이후에 expm 넣기\n",
    "        raise NotImplementedError(\"only taylor supported here\")\n",
    "\n",
    "    if renormalize:\n",
    "        K = K / (K.sum(1, keepdims=True) + 1e-12)\n",
    "    return K\n",
    "\n",
    "\n",
    "# --- 2) diffusion distance (dense K만 받으면 됨) ----\n",
    "def diffusion_distance_matrix(K, pi=None):\n",
    "    \"\"\"\n",
    "    K : (n,n) heat kernel, rows ~ distributions\n",
    "    pi: (n,) stationary approx\n",
    "    \"\"\"\n",
    "    n = K.shape[0]\n",
    "    if pi is None:\n",
    "        # row-average로 proxy\n",
    "        pi = K.mean(axis=0)\n",
    "    pi = np.asarray(pi, dtype=float).reshape(-1)\n",
    "    pi = pi / np.clip(pi.sum(), 1e-12, None)\n",
    "\n",
    "    W = np.diag(1.0 / np.sqrt(pi + 1e-12))\n",
    "\n",
    "    X = K @ W\n",
    "    sqnorm = np.sum(X * X, axis=1, keepdims=True)\n",
    "    G = X @ X.T\n",
    "    D2 = np.clip(sqnorm + sqnorm.T - 2 * G, 0.0, None)\n",
    "    return np.sqrt(D2)\n",
    "\n",
    "\n",
    "# --- 3) RKHS distance from kernel (dense) ----\n",
    "def rkhs_distance_matrix_from_kernel(K, force_sym=True):\n",
    "    if force_sym:\n",
    "        K = 0.5 * (K + K.T)\n",
    "    diag = np.diag(K).reshape(-1, 1)\n",
    "    D2 = np.clip(diag + diag.T - 2.0 * K, 0.0, None)\n",
    "    return np.sqrt(D2)\n",
    "\n",
    "\n",
    "# --- 4) sparse A에서도 한 번에 두 거리 뽑는 wrapper ----\n",
    "def diffusion_and_rkhs_distances(\n",
    "    A, t=1.0, method='taylor', order=2, pi=None\n",
    "):\n",
    "    \"\"\"\n",
    "    A : (n,n) dense or sparse adjacency\n",
    "    Returns:\n",
    "      D_diff : diffusion distance (from RW heat kernel)\n",
    "      D_rkhs : RKHS distance (from sym heat kernel)\n",
    "    \"\"\"\n",
    "    # diffusion: RW\n",
    "    K_rw = heat_kernel_from_adj(\n",
    "        A, t=t, lap='rw', method=method, order=order, renormalize=True\n",
    "    )\n",
    "    D_diff = diffusion_distance_matrix(K_rw, pi=pi)\n",
    "\n",
    "    # RKHS: symmetric\n",
    "    K_sym = heat_kernel_from_adj(\n",
    "        A, t=t, lap='sym', method=method, order=order, renormalize=False\n",
    "    )\n",
    "    D_rkhs = rkhs_distance_matrix_from_kernel(K_sym, force_sym=True)\n",
    "\n",
    "    return D_diff, D_rkhs\n",
    "\n",
    "\n",
    "# --- 5) geodesic도 sparse 받아서 처리 ----\n",
    "def all_pairs_geodesic(A, weighted=False):\n",
    "    \"\"\"\n",
    "    A : dense or sparse adjacency\n",
    "    \"\"\"\n",
    "    if sp.issparse(A):\n",
    "        G = A\n",
    "    else:\n",
    "        G = sp.csr_matrix(A if weighted else (A > 0).astype(float))\n",
    "    D = shortest_path(G, directed=False, unweighted=not weighted)\n",
    "    return D\n",
    "\n",
    "\n",
    "# --- 6) (참고) block feature는 원래 sparse랑 무관해서 그대로 ----\n",
    "def make_block_features(z, d=6, margin=2.0, noise=0.5, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    B = z.max() + 1\n",
    "    mu = np.zeros((B, d))\n",
    "    for b in range(B):\n",
    "        mu[b, b % d] = margin\n",
    "    FX = mu[z] + noise * rng.standard_normal((len(z), d))\n",
    "    return FX, mu\n",
    "\n",
    "# 사용 가능한 파일 확인\n",
    "files = sorted(TRAIN_PATH.glob(\"*.ply\"))\n",
    "# print(f\"#files: {len(files)}\")\n",
    "# if files[:3]: \n",
    "#     for f in files[:3]:\n",
    "#         print(\"e.g.\", f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa8704ad-ddcb-4a0d-a0eb-fe67bb31d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_s, F_s = load_ply_mesh(files[0])\n",
    "V_t, F_t = load_ply_mesh(files[1])\n",
    "n_s, n_t = len(V_s), len(V_t)\n",
    "a = b = np.ones((n_s,)) / n_s\n",
    "\n",
    "colors_src = (V_s - V_s.min(0)) / (V_s.max(0) - V_s.min(0) + 1e-12)\n",
    "mesh_src = to_mesh(V_s, F_s, colors_src)\n",
    "\n",
    "A_s = build_adj_from_mesh(V_s,F_s)\n",
    "A_t = build_adj_from_mesh(V_t,F_t)\n",
    "\n",
    "f_s = compute_fpfh_from_mesh(V_s,F_s)\n",
    "f_t = compute_fpfh_from_mesh(V_t,F_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b47ded28-21b3-42a5-96e7-62aca3805a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_heat = 1\n",
    "\n",
    "# Ds_sym = heat_kernel_from_adj(A_s, t=t_heat, lap='sym', method='taylor', order=2)\n",
    "# Dt_sym = heat_kernel_from_adj(A_t, t=t_heat, lap='sym', method='taylor', order=2)\n",
    "\n",
    "# Ds = rkhs_distance_matrix_from_kernel(Ds_sym) \n",
    "# Dt = rkhs_distance_matrix_from_kernel(Dt_sym)\n",
    "Ds = all_pairs_geodesic(A_s)\n",
    "Dt = all_pairs_geodesic(A_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "092ef08d-c9d1-4478-9906-1092d20b2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_f = cdist(f_s, f_t, metric=\"sqeuclidean\")\n",
    "C_f = cdist(V_s, V_t, metric=\"sqeuclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3734304-7b98-4690-a9a2-658151f49e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_coupling_with_marginals(p, q, max_iter=1000, tol=1e-9, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    K = rng.random((len(p), len(q)))\n",
    "    u = np.ones_like(p)\n",
    "    v = np.ones_like(q)\n",
    "    for _ in range(max_iter):\n",
    "        u_prev = u.copy()\n",
    "        u = p / (K @ v)\n",
    "        v = q / (K.T @ u)\n",
    "        if np.linalg.norm(u - u_prev, 1) < tol:\n",
    "            break\n",
    "    P = np.diag(u) @ K @ np.diag(v)\n",
    "    P /= P.sum()  # optional normalization\n",
    "    return P\n",
    "\n",
    "pi = random_coupling_with_marginals(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a57273-3b88-40ee-8670-902b0ad9cb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 001] gap=1.211e-01 obj_feat=1.283e-01 obj_struct=1.944e-03\n",
      "[Iter 002] gap=4.036e-02 obj_feat=4.969e-02 obj_struct=1.260e-03\n",
      "[Iter 003] gap=2.048e-02 obj_feat=3.058e-02 obj_struct=1.010e-03\n",
      "[Iter 004] gap=1.208e-02 obj_feat=2.297e-02 obj_struct=8.515e-04\n",
      "[Iter 005] gap=8.316e-03 obj_feat=1.926e-02 obj_struct=7.970e-04\n",
      "[Iter 006] gap=5.973e-03 obj_feat=1.712e-02 obj_struct=7.497e-04\n",
      "[Iter 007] gap=4.489e-03 obj_feat=1.580e-02 obj_struct=7.101e-04\n",
      "[Iter 008] gap=3.804e-03 obj_feat=1.490e-02 obj_struct=7.090e-04\n",
      "[Iter 009] gap=3.140e-03 obj_feat=1.425e-02 obj_struct=6.796e-04\n",
      "[Iter 010] gap=2.354e-03 obj_feat=1.376e-02 obj_struct=6.631e-04\n",
      "[Iter 011] gap=2.065e-03 obj_feat=1.343e-02 obj_struct=6.509e-04\n",
      "[Iter 012] gap=1.634e-03 obj_feat=1.317e-02 obj_struct=6.353e-04\n",
      "[Iter 013] gap=1.639e-03 obj_feat=1.298e-02 obj_struct=6.271e-04\n",
      "[Iter 014] gap=1.361e-03 obj_feat=1.281e-02 obj_struct=6.184e-04\n",
      "[Iter 015] gap=1.216e-03 obj_feat=1.267e-02 obj_struct=6.100e-04\n",
      "[Iter 016] gap=9.982e-04 obj_feat=1.256e-02 obj_struct=6.048e-04\n",
      "[Iter 017] gap=9.660e-04 obj_feat=1.247e-02 obj_struct=6.064e-04\n",
      "[Iter 018] gap=9.434e-04 obj_feat=1.239e-02 obj_struct=6.037e-04\n",
      "[Iter 019] gap=6.744e-04 obj_feat=1.232e-02 obj_struct=6.008e-04\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "alpha = 0.2\n",
    "T = 200\n",
    "\n",
    "start_time = time.time()  # 시작 시간 기록\n",
    "\n",
    "model = FOT.ConvexFusedTransport(\n",
    "    alpha=alpha,\n",
    "    fw_max_iter=T,\n",
    "    fw_stepsize='classic',\n",
    "    tol=1e-40,\n",
    "    lmo_method='emd',\n",
    "    pre_Cf=C_f,\n",
    "    pre_DX=Ds,\n",
    "    pre_DY=Dt,\n",
    "    verbose=2\n",
    ").fit(\n",
    "    X=np.array(range(n_s)).reshape(-1, 1),\n",
    "    Y=np.array(range(n_t)).reshape(-1, 1),\n",
    "    FX=None, FY=None, init=pi,\n",
    "    return_hard_assignment=True\n",
    ")\n",
    "\n",
    "end_time = time.time()  # 종료 시간 기록\n",
    "elapsed = end_time - start_time\n",
    "\n",
    "print(f\"\\nTotal runtime: {elapsed:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d29f98-3155-4e20-82bf-b22696770623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors_FOT = transfer_colors_soft(model.P_, colors_src) \n",
    "# mesh_FOT = to_mesh(V_t, F_t, colors_FOT)\n",
    "\n",
    "# offset = np.array([1.2*V_s[:, 0].ptp(), 0, 0])\n",
    "# mesh_FOT.translate(offset)\n",
    "\n",
    "# o3d.visualization.draw_geometries([mesh_src,mesh_FOT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b19693-2f27-4eb5-9d45-b1d2a1b00760",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_FGW = ot.gromov.fused_gromov_wasserstein(\n",
    "    C_f, Ds, Dt, G_0=pi,\n",
    "    alpha=alpha, loss_fun='square_loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b897b-29df-48a7-9e97-0e24c0a1232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_FGW = transfer_colors_soft(T_FGW, colors_src) \n",
    "mesh_FGW = to_mesh(V_t, F_t, colors_FGW)\n",
    "\n",
    "offset = np.array([2.4*V_s[:, 0].ptp(), 0, 0])\n",
    "mesh_FGW.translate(offset)\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh_src,mesh_FOT,mesh_FGW])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc80a37e-be49-48ee-b2ea-3d7d023a277c",
   "metadata": {},
   "source": [
    "## Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b5c3d1-d5cb-479f-a8b0-0111f85ebe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(model.obj_history_)), model.obj_history_, marker='o')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Objective')\n",
    "plt.title('Objective per Iteration')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a90893-b1f2-4a6c-942d-6461827c0bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
